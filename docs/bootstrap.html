<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Computational Statistics - Summary</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="Computational Statistics - Summary">
  <meta name="generator" content="bookdown 0.3 and GitBook 2.6.7">

  <meta property="og:title" content="Computational Statistics - Summary" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Computational Statistics - Summary" />
  
  
  

<meta name="author" content="Lorenz Walthert">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="cross-validation.html">
<link rel="next" href="classification.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>


  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Hello World</a></li>
<li class="chapter" data-level="2" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html"><i class="fa fa-check"></i><b>2</b> Multiple Linear Regression</a></li>
<li class="chapter" data-level="3" data-path="nonparametric-density-estimation.html"><a href="nonparametric-density-estimation.html"><i class="fa fa-check"></i><b>3</b> Nonparametric Density Estimation</a></li>
<li class="chapter" data-level="4" data-path="nonparametric-regression.html"><a href="nonparametric-regression.html"><i class="fa fa-check"></i><b>4</b> Nonparametric Regression</a></li>
<li class="chapter" data-level="5" data-path="cross-validation.html"><a href="cross-validation.html"><i class="fa fa-check"></i><b>5</b> Cross Validation</a></li>
<li class="chapter" data-level="6" data-path="bootstrap.html"><a href="bootstrap.html"><i class="fa fa-check"></i><b>6</b> Bootstrap</a><ul>
<li class="chapter" data-level="6.1" data-path="bootstrap.html"><a href="bootstrap.html#motivation"><i class="fa fa-check"></i><b>6.1</b> Motivation</a></li>
<li class="chapter" data-level="6.2" data-path="bootstrap.html"><a href="bootstrap.html#the-bootstrap-distribution"><i class="fa fa-check"></i><b>6.2</b> The bootstrap distribution</a></li>
<li class="chapter" data-level="6.3" data-path="bootstrap.html"><a href="bootstrap.html#bootstrap-consistency"><i class="fa fa-check"></i><b>6.3</b> Bootstrap Consistency</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="classification.html"><a href="classification.html"><i class="fa fa-check"></i><b>7</b> Classification</a><ul>
<li class="chapter" data-level="7.1" data-path="classification.html"><a href="classification.html#indirect-classification---the-bayes-classifier"><i class="fa fa-check"></i><b>7.1</b> Indirect Classification - The Bayes Classifier</a></li>
<li class="chapter" data-level="7.2" data-path="classification.html"><a href="classification.html#direct-classification---the-discriminant-view"><i class="fa fa-check"></i><b>7.2</b> Direct Classification - The Discriminant View</a><ul>
<li class="chapter" data-level="7.2.1" data-path="classification.html"><a href="classification.html#lda"><i class="fa fa-check"></i><b>7.2.1</b> LDA</a></li>
<li class="chapter" data-level="7.2.2" data-path="classification.html"><a href="classification.html#qda"><i class="fa fa-check"></i><b>7.2.2</b> QDA</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="flexible-regression-and-classification-methods.html"><a href="flexible-regression-and-classification-methods.html"><i class="fa fa-check"></i><b>8</b> Flexible regression and classification methods</a></li>
<li class="chapter" data-level="9" data-path="bagging-and-boosting.html"><a href="bagging-and-boosting.html"><i class="fa fa-check"></i><b>9</b> Bagging and Boosting</a></li>
<li class="chapter" data-level="10" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>10</b> Introduction</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Computational Statistics - Summary</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="bootstrap" class="section level1">
<h1><span class="header-section-number">Chapter 6</span> Bootstrap</h1>
<ul>
<li>Bootstrap can be summarized as “simulating from an estimated model”</li>
<li>It is used for inference (confidence intervals / hypothesis testing)</li>
<li>It can also be used for estimating the predictive power of a model (similarly to cross validation) via out-of-bootstrap generalization error</li>
</ul>
<div id="motivation" class="section level2">
<h2><span class="header-section-number">6.1</span> Motivation</h2>
<p>Consider i.i.d. data. <span class="math display">\[ Z_1, .. Z_n \sim\ P \;\; with \; \;Z_i = (X_i, Y_i)\]</span> And assume a statistical procedure <span class="math display">\[ \hat{\theta} = g(Z_1, ..., Z_n) \]</span> <span class="math inline">\(g(\cdot)\)</span> can be a point estimator for a regression coefficient, a non-parametric curve estimator or a generalization error estimator based on one new observation, e.g. <span class="math display">\[ \hat{\theta}_{n+1} = g(Z_1, ..., Z_{new}) = (Y_{new} - m_{Z_1, ..., Z_{new}}(X_{new})^2 \]</span> To make inference, we want to know the distribution of <span class="math inline">\(\hat{\theta}\)</span>. For some cases, we can derive the distribution analytically if we know the distribution <span class="math inline">\(P\)</span>. The central limit theorem states that the sum of random variables approximates a normal distribution with <span class="math inline">\(n \rightarrow \infty\)</span>. Therefore, we know <span class="math display">\[ \hat{\theta}_{n \rightarrow \infty} = n^{-1}\sum x_i \sim N(\mu_x, \sigma_x^2 / n) \]</span> for <em>any</em> <span class="math inline">\(P\)</span>. However, if <span class="math inline">\(\hat{\theta}\)</span> is not a sum of random variables, and the CLT does not apply, it’s not as straightforward to obtain the distribution of <span class="math inline">\(\hat{\theta}\)</span>. Also, if <span class="math inline">\(P\)</span> is not the normal distribution, but some other distribution, we can’t find the distribution of <span class="math inline">\(\hat{\theta}\)</span> easily. The script mentions the median estimator as an example for which the variance already depends on the density of <span class="math inline">\(P\)</span>. Hence, deriving properties of estimators analytically, even the asymptotic ones only, is a pain. Therefore, if we knew <span class="math inline">\(P\)</span>, we could simply simulate many times and get the distribution of <span class="math inline">\(\hat{\theta}\)</span> this way. That is, draw many <span class="math inline">\((X_i, Y_i)\)</span> from that distribution and compute <span class="math inline">\(\hat{\theta}\)</span> for each draw.</p>
<p>The problem is that we don’t know <span class="math inline">\(P\)</span>. But we have a data sample that was generated from <span class="math inline">\(P\)</span>. Hence, we can instead take the <strong>empirical</strong> distribution <span class="math inline">\(\hat{P}\)</span>that places probability mass of <span class="math inline">\(1/n\)</span> on each observation, draw a sample from this distribution (which is simply drawing uniformly from our sample with replacement) and compute our estimate of interest from this sample. <span class="math display">\[ \hat{\theta}^{*} = g({Z_1}^{*}, ..., {Z_{new}}^{*})\]</span> We can do that many times to get an approximate distribution for <span class="math inline">\(\hat{\theta}\)</span>. A crucial assumption is that <span class="math inline">\(\hat{P}\)</span> ressembles <span class="math inline">\(P\)</span>. If our data is not i.i.d, this may not be the case and hence bootsrapping might be missleading. Below, we can see that i.i.d. sampling ressembles the true distribution quite well, wherease biased sampling obviously does not. We produce a sample that places higher probability mass to the large (absolute) values. <img src="Computational_Statistics_-_Summary_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p>We can summarize the bootstrap procedure as follows.</p>
<ul>
<li>draw a bootstrap sample <span class="math inline">\({Z_1}^{*}, ..., {Z_{new}}^{*}\)</span></li>
<li>compute your estimator <span class="math inline">\(\hat{\theta}\)</span> based on that sample.</li>
<li>repeat the first two steps <span class="math inline">\(B\)</span> times to get bootstrap estimators <span class="math inline">\(\hat{\theta}_1, ..., \hat{\theta}_B\)</span> and therefore an estimate of the distribution of <span class="math inline">\(\hat{\theta}\)</span>.</li>
</ul>
<p>Use the <span class="math inline">\(B\)</span> estimated boostrap estimators as approxmimations for the bootstrap expectation, quantiles and so on. <span class="math inline">\(\mathbb{E}[\hat{\theta}^*_n] \approx B^{-1}\sum\limits_{j = 1}^n \hat{\theta}^{* j}_n\)</span></p>
</div>
<div id="the-bootstrap-distribution" class="section level2">
<h2><span class="header-section-number">6.2</span> The bootstrap distribution</h2>
<p>With <span class="math inline">\(P^*\)</span>, we denote the boostrap distribution, which is the conditional probability distribution introduced by sampling i.i.d. from the empirical distribution <span class="math inline">\(\hat{P}\)</span>. Hence, <span class="math inline">\(P^*\)</span> of <span class="math inline">\(\hat{\theta}^*\)</span> is the distribution that arrises from sampling i.i.d. from <span class="math inline">\(\hat{P}\)</span> and applying the transformation <span class="math inline">\(g(\cdot)\)</span> to the data. Conditioning on the data allows us to treat <span class="math inline">\(\hat{P}\)</span> as fixed.</p>
</div>
<div id="bootstrap-consistency" class="section level2">
<h2><span class="header-section-number">6.3</span> Bootstrap Consistency</h2>
<p>The bootstrap is is called consistent if <span class="math display">\[ \mathbb{P}[a_n(\hat{\theta} - \theta) \leq x ] - \mathbb{P}[a_n(\hat{\theta} - \theta) \leq x ] \rightarrow 0\]</span></p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="cross-validation.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="classification.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
