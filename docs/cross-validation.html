<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Computational Statistics - Summary</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="Computational Statistics - Summary">
  <meta name="generator" content="bookdown 0.3 and GitBook 2.6.7">

  <meta property="og:title" content="Computational Statistics - Summary" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Computational Statistics - Summary" />
  
  
  

<meta name="author" content="Lorenz Walthert">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="nonparametric-regression.html">
<link rel="next" href="bootstrap.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>


  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html"><i class="fa fa-check"></i><b>2</b> Multiple Linear Regression</a></li>
<li class="chapter" data-level="3" data-path="nonparametric-density-estimation.html"><a href="nonparametric-density-estimation.html"><i class="fa fa-check"></i><b>3</b> Nonparametric Density Estimation</a></li>
<li class="chapter" data-level="4" data-path="nonparametric-regression.html"><a href="nonparametric-regression.html"><i class="fa fa-check"></i><b>4</b> Nonparametric Regression</a></li>
<li class="chapter" data-level="5" data-path="cross-validation.html"><a href="cross-validation.html"><i class="fa fa-check"></i><b>5</b> Cross Validation</a><ul>
<li class="chapter" data-level="5.1" data-path="cross-validation.html"><a href="cross-validation.html#motivation-and-core-idea"><i class="fa fa-check"></i><b>5.1</b> Motivation and Core Idea</a></li>
<li class="chapter" data-level="5.2" data-path="cross-validation.html"><a href="cross-validation.html#loss-function"><i class="fa fa-check"></i><b>5.2</b> Loss Function</a></li>
<li class="chapter" data-level="5.3" data-path="cross-validation.html"><a href="cross-validation.html#implementation"><i class="fa fa-check"></i><b>5.3</b> Implementation</a><ul>
<li class="chapter" data-level="5.3.1" data-path="cross-validation.html"><a href="cross-validation.html#leave-one-out"><i class="fa fa-check"></i><b>5.3.1</b> Leave-one-out</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="cross-validation.html"><a href="cross-validation.html#k-fold-cross-validation"><i class="fa fa-check"></i><b>5.4</b> K-fold Cross-Validation</a><ul>
<li class="chapter" data-level="5.4.1" data-path="cross-validation.html"><a href="cross-validation.html#random-division-into-test-and-training-data-set"><i class="fa fa-check"></i><b>5.4.1</b> Random Division into test and training data set</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="cross-validation.html"><a href="cross-validation.html#properties-of-the-different-schemes"><i class="fa fa-check"></i><b>5.5</b> Properties of the different schemes</a></li>
<li class="chapter" data-level="5.6" data-path="cross-validation.html"><a href="cross-validation.html#shortcuts-for-some-linear-fitting-operators"><i class="fa fa-check"></i><b>5.6</b> Shortcuts for (some) linear fitting operators</a></li>
<li class="chapter" data-level="5.7" data-path="cross-validation.html"><a href="cross-validation.html#examples"><i class="fa fa-check"></i><b>5.7</b> Examples</a><ul>
<li class="chapter" data-level="5.7.1" data-path="cross-validation.html"><a href="cross-validation.html#practical-cv-in-r"><i class="fa fa-check"></i><b>5.7.1</b> Practical CV in R</a></li>
<li class="chapter" data-level="5.7.2" data-path="cross-validation.html"><a href="cross-validation.html#parameter-tuning"><i class="fa fa-check"></i><b>5.7.2</b> Parameter Tuning</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="bootstrap.html"><a href="bootstrap.html"><i class="fa fa-check"></i><b>6</b> Bootstrap</a><ul>
<li class="chapter" data-level="6.1" data-path="bootstrap.html"><a href="bootstrap.html#motivation"><i class="fa fa-check"></i><b>6.1</b> Motivation</a></li>
<li class="chapter" data-level="6.2" data-path="bootstrap.html"><a href="bootstrap.html#the-bootstrap-distribution"><i class="fa fa-check"></i><b>6.2</b> The Bootstrap Distribution</a></li>
<li class="chapter" data-level="6.3" data-path="bootstrap.html"><a href="bootstrap.html#bootstrap-consistency"><i class="fa fa-check"></i><b>6.3</b> Bootstrap Consistency</a></li>
<li class="chapter" data-level="6.4" data-path="bootstrap.html"><a href="bootstrap.html#boostrap-confidence-intervals"><i class="fa fa-check"></i><b>6.4</b> Boostrap Confidence Intervals</a></li>
<li class="chapter" data-level="6.5" data-path="bootstrap.html"><a href="bootstrap.html#boostrap-estimator-of-the-generalization-error"><i class="fa fa-check"></i><b>6.5</b> Boostrap Estimator of the Generalization Error</a></li>
<li class="chapter" data-level="6.6" data-path="bootstrap.html"><a href="bootstrap.html#out-of-boostrap-sample-for-estimating-the-ge"><i class="fa fa-check"></i><b>6.6</b> Out-of-Boostrap sample for estimating the GE</a></li>
<li class="chapter" data-level="6.7" data-path="bootstrap.html"><a href="bootstrap.html#double-boostrap-confidence-intervals"><i class="fa fa-check"></i><b>6.7</b> Double Boostrap Confidence Intervals</a></li>
<li class="chapter" data-level="6.8" data-path="bootstrap.html"><a href="bootstrap.html#three-versions-of-boostrap"><i class="fa fa-check"></i><b>6.8</b> Three Versions of Boostrap</a><ul>
<li class="chapter" data-level="6.8.1" data-path="bootstrap.html"><a href="bootstrap.html#non-parametric-regression"><i class="fa fa-check"></i><b>6.8.1</b> Non-parametric Regression</a></li>
<li class="chapter" data-level="6.8.2" data-path="bootstrap.html"><a href="bootstrap.html#parametric-boostrap"><i class="fa fa-check"></i><b>6.8.2</b> Parametric Boostrap</a></li>
<li class="chapter" data-level="6.8.3" data-path="bootstrap.html"><a href="bootstrap.html#model-based-bootstrap"><i class="fa fa-check"></i><b>6.8.3</b> Model-Based Bootstrap</a></li>
</ul></li>
<li class="chapter" data-level="6.9" data-path="bootstrap.html"><a href="bootstrap.html#conclusion"><i class="fa fa-check"></i><b>6.9</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="classification.html"><a href="classification.html"><i class="fa fa-check"></i><b>7</b> Classification</a><ul>
<li class="chapter" data-level="7.1" data-path="classification.html"><a href="classification.html#indirect-classification---the-bayes-classifier"><i class="fa fa-check"></i><b>7.1</b> Indirect Classification - The Bayes Classifier</a></li>
<li class="chapter" data-level="7.2" data-path="classification.html"><a href="classification.html#direct-classification---the-discriminant-view"><i class="fa fa-check"></i><b>7.2</b> Direct Classification - The Discriminant View</a><ul>
<li class="chapter" data-level="7.2.1" data-path="classification.html"><a href="classification.html#lda"><i class="fa fa-check"></i><b>7.2.1</b> LDA</a></li>
<li class="chapter" data-level="7.2.2" data-path="classification.html"><a href="classification.html#qda"><i class="fa fa-check"></i><b>7.2.2</b> QDA</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="classification.html"><a href="classification.html#indirect-classification---the-view-of-logistic-regression"><i class="fa fa-check"></i><b>7.3</b> Indirect Classification - The View of Logistic Regression</a></li>
<li class="chapter" data-level="7.4" data-path="classification.html"><a href="classification.html#discriminant-analysis-or-logistic-regression"><i class="fa fa-check"></i><b>7.4</b> Discriminant Analysis or Logistic Regression?</a></li>
<li class="chapter" data-level="7.5" data-path="classification.html"><a href="classification.html#multiclass-case-j-2"><i class="fa fa-check"></i><b>7.5</b> Multiclass case (J &gt; 2)</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="flexible-regression-and-classification-methods.html"><a href="flexible-regression-and-classification-methods.html"><i class="fa fa-check"></i><b>8</b> Flexible regression and classification methods</a><ul>
<li class="chapter" data-level="8.1" data-path="flexible-regression-and-classification-methods.html"><a href="flexible-regression-and-classification-methods.html#additive-models"><i class="fa fa-check"></i><b>8.1</b> Additive Models</a><ul>
<li class="chapter" data-level="8.1.1" data-path="flexible-regression-and-classification-methods.html"><a href="flexible-regression-and-classification-methods.html#structure"><i class="fa fa-check"></i><b>8.1.1</b> Structure</a></li>
<li class="chapter" data-level="8.1.2" data-path="flexible-regression-and-classification-methods.html"><a href="flexible-regression-and-classification-methods.html#fitting-procedure"><i class="fa fa-check"></i><b>8.1.2</b> Fitting Procedure</a></li>
<li class="chapter" data-level="8.1.3" data-path="flexible-regression-and-classification-methods.html"><a href="flexible-regression-and-classification-methods.html#additive-models-in-r"><i class="fa fa-check"></i><b>8.1.3</b> Additive Models in R</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="flexible-regression-and-classification-methods.html"><a href="flexible-regression-and-classification-methods.html#mars"><i class="fa fa-check"></i><b>8.2</b> MARS</a><ul>
<li class="chapter" data-level="8.2.1" data-path="flexible-regression-and-classification-methods.html"><a href="flexible-regression-and-classification-methods.html#details-for-dummies"><i class="fa fa-check"></i><b>8.2.1</b> Details for Dummies</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="flexible-regression-and-classification-methods.html"><a href="flexible-regression-and-classification-methods.html#example"><i class="fa fa-check"></i><b>8.3</b> Example</a></li>
<li class="chapter" data-level="8.4" data-path="flexible-regression-and-classification-methods.html"><a href="flexible-regression-and-classification-methods.html#neural-networks"><i class="fa fa-check"></i><b>8.4</b> Neural Networks</a><ul>
<li class="chapter" data-level="8.4.1" data-path="flexible-regression-and-classification-methods.html"><a href="flexible-regression-and-classification-methods.html#fitting-neural-networks-in-r"><i class="fa fa-check"></i><b>8.4.1</b> Fitting Neural Networks (in R)</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="flexible-regression-and-classification-methods.html"><a href="flexible-regression-and-classification-methods.html#projection-pursuit-regression"><i class="fa fa-check"></i><b>8.5</b> Projection Pursuit Regression</a><ul>
<li class="chapter" data-level="8.5.1" data-path="flexible-regression-and-classification-methods.html"><a href="flexible-regression-and-classification-methods.html#proejction-pursuit-example"><i class="fa fa-check"></i><b>8.5.1</b> Proejction Pursuit Example</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="bagging-and-boosting.html"><a href="bagging-and-boosting.html"><i class="fa fa-check"></i><b>9</b> Bagging and Boosting</a></li>
<li class="chapter" data-level="10" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>10</b> Introduction</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Computational Statistics - Summary</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="cross-validation" class="section level1">
<h1><span class="header-section-number">Chapter 5</span> Cross Validation</h1>
<div id="motivation-and-core-idea" class="section level2">
<h2><span class="header-section-number">5.1</span> Motivation and Core Idea</h2>
<p>Cross-validation is a tool for estimating the performance of an algorithm on new data points, the so-called the generalization error. An estimate of the generalization allows us to do two important things:</p>
<ul>
<li>Tuning the parameters of a statistical technique.</li>
<li>Comparing statistical techniques with regard to their accuracy.</li>
</ul>
<p>If we use the <strong>training data</strong> to evaluate the performance of an algorithm, this estimate will be over-optimistic because an estimator is usually obtained by minimizing some sort of error in the training data. Therefore, we use a separate data pool, called the <strong>test data</strong> to evaluate the performance out of sample. Consider the regression function estimate <span class="math inline">\(\hat{m}\)</span> based on a sample <span class="math inline">\((X_1, ..., X_n.)\)</span>. By increasing the number of parameters in the model and by allowing for interactions between them, we can make the regression model fitting arbitrarily well to the data. However, such an extremely complex model will not perform as well with new data, that is, will not generalize well to other data sets, since we essentially modeled also a lot of noise. To estimate the performance of an algorithm on a new sample, we introduce the following notation: <span class="math display">\[ l^{-1}\sum\limits_{i = 1}^l\rho(Y_{new, i}, \hat{g}(X_{new, l}))\]</span> Where <span class="math inline">\(\rho\)</span> is a loss function to be evaluated on the new data points <span class="math inline">\((Y_{new, 1}, ..., Y_{new, l})\)</span> and the prediction made for <span class="math inline">\((X_{new, 1}, ..., X_{new, l})\)</span> with the function <span class="math inline">\(\hat{g}\)</span>, which was estimated from the training data <span class="math inline">\((X_1, ..., X_n)\)</span>. When <span class="math inline">\(l\)</span> gets large, this approximates the <strong>test error</strong> <span class="math display">\[\mathbb{E}_{(X_{new}, Y_{new})}[\rho(Y_{new}, \hat{m}(X_{new})]\]</span> which is still a function of the training data (since it is conditional on the training data). Note that the <em>test error</em> is not the same as the <strong>generalization error</strong>. The latter is an expectation over both the training and the test data. The typical relationship between the test error and the training error is depicted in the figure below.</p>
<p><img src="figures/ge.jpg" width="650px" /></p>
<p>The optimal model complexity is at around <span class="math inline">\(20\)</span> degrees of freedom. With more degrees of freedom, the test set error increases again. We start to model noise. This is also called overfitting.</p>
</div>
<div id="loss-function" class="section level2">
<h2><span class="header-section-number">5.2</span> Loss Function</h2>
<p>Depending on the application, one can imagine different loss-functions. For example the squared deviance from the <em>true</em> value is often used, i.e. <span class="math display">\[n^{-1}\sum\limits_{i = 1}^n\rho(Y_i, \hat{m}(X_i)) = n^{-1}\sum\limits_{i = 1}^n(Y_i - \hat{m}(X_i))^2\]</span> Hence, larger deviance is penalized over-proportionally. For classification, one often uses the zero-one error, i.e. <span class="math display">\[n^{-1}\sum\limits_{i = 1}^n1_{\hat{m}(X_i) = Y_i}\]</span> However, it might also be appropriate to use asymmetric loss functions if false negatives are worse than false positives (i.e. for cancer tests).</p>
</div>
<div id="implementation" class="section level2">
<h2><span class="header-section-number">5.3</span> Implementation</h2>
<p>There are different ways to do cross validation while adhering to the principles introduced above.</p>
<div id="leave-one-out" class="section level3">
<h3><span class="header-section-number">5.3.1</span> Leave-one-out</h3>
<ul>
<li>Use all but one data point to construct a model and predict on the remaining data point.</li>
<li>Do that <span class="math inline">\(n\)</span> times until all <span class="math inline">\(n\)</span> points were used for prediction once.</li>
<li>Compute the test error as an average over all n errors measured, i.e</li>
</ul>
<p><span class="math display">\[n^{-1}\sum\limits_{i = 1}^n \rho{(Y_{i}, \hat{m}_{n-1}^{-i}(X_i)})\]</span> And use that as an approximation of the <em>generalization error</em>.</p>
</div>
</div>
<div id="k-fold-cross-validation" class="section level2">
<h2><span class="header-section-number">5.4</span> K-fold Cross-Validation</h2>
<p>This method is best explained with a picture.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knitr::<span class="kw">include_graphics</span>(<span class="st">&quot;figures/k_fold_cv.png&quot;</span>)</code></pre></div>
<p><img src="figures/k_fold_cv.png" width="650px" /> Here, one splits the data set into k equally sized folds. Then, the idea is to use all <span class="math inline">\(k-1\)</span> folds to build a model and the remaining fold to evaluate the model. Then, we average the <span class="math inline">\(k\)</span> estimates of the generalization error. Or in mathematical notation:</p>
<p><span class="math display">\[K^{-1} \sum\limits_{k = 1}^K |B_k|^{-1} \sum\limits_{i \in B_k}\rho({Y_{i}, \hat{m}^{-B_k}_{n-|B_k|}(X_i))}\]</span></p>
<p>Note that leave-one out cv is the same as k-fold cross validation with <span class="math inline">\(=n\)</span>.</p>
<div id="random-division-into-test-and-training-data-set" class="section level3">
<h3><span class="header-section-number">5.4.1</span> Random Division into test and training data set</h3>
<p>The problem of K-fold cross-validation is that it depends on <strong>one realization</strong> of the split into k folds. Instead, we can generalize leave-one-out to leave-d-out. That means, we remove <span class="math inline">\(d\)</span> observations from our initial data, apply our estimation procedure and evaluate on the <span class="math inline">\(d\)</span> observations. <span class="math display">\[\hat{\theta}^{-C_k}_{n-k} \;\;\; \text{for all possible subsets}\;\; C_k, \;\; k=1, ..., {\binom{n}{d}}\]</span> The generalization error can be estimated with <span class="math display">\[{\binom{n}{d}}^{-1}\sum\limits_{k = 1}^{\binom{n}{d}} d^{-1}\sum\limits_{i \in C_k} \rho(Y_i, \hat{m}^{-C_k}_{n-d}(X_i))\]</span> For <span class="math inline">\(d &gt; 3\)</span>, the computational burden becomes immense. For that reason, instead of considering all <span class="math inline">\({\binom{n}{d}}\)</span> sets, we can uniformly draw <span class="math inline">\(B\)</span> sets (<span class="math inline">\(C_1^*, ... C_B^*\)</span>) from <span class="math inline">\(C_1, ..., C_{\binom{n}{d}}\)</span> <em>without replacement</em>. For <span class="math inline">\(B=\binom{n}{d}\)</span>, we obviously get the full leave-d-out solution. The <strong>computational cost</strong> for computing such an approximation to the leave-d-out is linear in <span class="math inline">\(B\)</span> (since evaluating is almost for free). For leave-one-out, the cost is linear in <span class="math inline">\(n\)</span> in the same way. Hence, the stochastic approximation for leave-d-out can be even smaller than for leave-one-out if <span class="math inline">\(B &lt; n\)</span>.</p>
</div>
</div>
<div id="properties-of-the-different-schemes" class="section level2">
<h2><span class="header-section-number">5.5</span> Properties of the different schemes</h2>
<ul>
<li><strong>leave-one-out</strong> is an asymptotically <strong>unbiased</strong> estimator for the generalization error and the true prediction. However, we use a sample size <span class="math inline">\(n-1\)</span> instead of <span class="math inline">\(n\)</span>, which causes a slight bias (meaning we have less data as we do in a real world scenario, which most likely makes the CV score a tiny little bit worse than it should be). Because the training sets are very similar to each other the leave-one-out scheme has a <strong>large variance</strong>.</li>
<li><strong>leave-d-out</strong> has a <strong>higher bias</strong> than leave-one-out because the sample size is even smaller than <span class="math inline">\(n-1\)</span> (for <span class="math inline">\(d&gt;1\)</span>). However, since we aggregate over more (<span class="math inline">\(\binom{n}{d}\)</span> instead of <span class="math inline">\(n\)</span>) cv scores, which can be shown to decrease the variance of the final cv estimator.</li>
<li><strong>k-fold</strong> cv has a <strong>higher bias</strong> than both leave one out.</li>
</ul>
</div>
<div id="shortcuts-for-some-linear-fitting-operators" class="section level2">
<h2><span class="header-section-number">5.6</span> Shortcuts for (some) linear fitting operators</h2>
<p>Leave-one-out cv score for some linear fitting procedures such as least squares or smoothing spline can be computed via a shortcut when our loss function is <span class="math inline">\(\rho(y, \hat{y}) = |y-\hat{y}|^2\)</span>. In particular, we can compute the estimator for such a linear fitting procedure <strong>once</strong>, compute the linear fitting operator <span class="math inline">\(S\)</span>, which satisfies <span class="math inline">\(\mathbf{Y} = \mathbf{SY}\)</span> and plug it in this formula: <span class="math display">\[n^{-1}\sum\limits_{i = 1}^n \Bigg(\frac{Y_i - \hat{m}(X_i)}{1-S_{ii}}\Bigg)^2\]</span> Computing <span class="math inline">\(\mathbf{S}\)</span> requires <span class="math inline">\(O(n)\)</span> operations (see exercises).</p>
<p>Historically, it has been computationally easier to compute the trace of <span class="math inline">\(\mathbf{S}\)</span> so there is also a quantity called generalized cross validation (which is a misleading terminology), which coincides with the formula above in certain cases.</p>
</div>
<div id="examples" class="section level2">
<h2><span class="header-section-number">5.7</span> Examples</h2>
<div id="practical-cv-in-r" class="section level3">
<h3><span class="header-section-number">5.7.1</span> Practical CV in R</h3>
<p>Key concepts to do CV are</p>
<ul>
<li>Do not split the data, split the indices of the data and work with them if ever possible and subset the data. <code>sample()</code> is your friend.</li>
<li>use <code>purrr::map()</code> and friends to “loop” over data.</li>
<li>Always work with lists, never work with data frames of indices. The reason is that data frames have structural constrains (all columns must have same number of elements) that are not natural in some situations. For example, out-of-bootstrap cv <em>does</em> have the same number of observations in the training set, but not in the test set.</li>
<li>In conjunction with <code>sample()</code>, you can use <code>purrr::rerun</code> or <code>replicate</code> to create lists of indices.</li>
<li>use helper function to solve “the small problems in the big problem”.</li>
</ul>
<p>Let’s first declare our functions.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;purrr&quot;</span>)
<span class="kw">data</span>(ozone, <span class="dt">package =</span> <span class="st">&quot;gss&quot;</span>)

<span class="co">#&#39; Estimate the generalization error of a ridge regression</span>
<span class="co">#&#39; @param test Test indices.</span>
<span class="co">#&#39; @param train Train indices.</span>
<span class="co">#&#39; @param .data The data.</span>
<span class="co">#&#39; @param lamda The lamda parameter for the ridge regression.</span>
ge_ridge &lt;-<span class="st"> </span>function(test, train, .data, lambda) {
  fit &lt;-<span class="st"> </span>MASS::<span class="kw">lm.ridge</span>(upo3~., 
                  <span class="dt">lambda =</span> lambda,
                  <span class="dt">data =</span> .data[train,])
  pred &lt;-<span class="st"> </span><span class="kw">as.matrix</span>(<span class="kw">cbind</span>(<span class="dv">1</span>, .data[test, -<span class="dv">1</span>])) %*%<span class="st"> </span><span class="kw">coef</span>(fit)
  <span class="kw">mean</span>((pred -<span class="st"> </span>.data[test,]$upo3)^<span class="dv">2</span>)
}


##  ............................................................................
##  functions to return list with indices                                   ####


get_boostrap_mat &lt;-<span class="st"> </span>function(B, n) {
  <span class="kw">rerun</span>(B, <span class="kw">sample</span>(n, n, <span class="dt">replace =</span> <span class="ot">TRUE</span>))
  
}

get_all_mat &lt;-<span class="st"> </span>function(B, n) {
  <span class="kw">rerun</span>(B, <span class="dv">1</span>:n)
}

get_complement &lt;-<span class="st"> </span>function(mat, n){
  <span class="kw">map</span>(mat, ~<span class="kw">setdiff</span>(<span class="dv">1</span>:n, .x))
}

get_k_fold &lt;-<span class="st"> </span>function(k, n) {
  step &lt;-<span class="st"> </span><span class="kw">trunc</span>(n/k)
  current &lt;-<span class="st"> </span><span class="kw">list</span>()
  for (i in (<span class="dv">0</span>:(k<span class="dv">-1</span>) *<span class="st"> </span>step +<span class="st"> </span><span class="dv">1</span>))  {
    current &lt;-<span class="st"> </span><span class="kw">append</span>(current, <span class="kw">list</span>(
      (i:(i+step<span class="dv">-1</span>))
    )
    )
  }
  current
}</code></pre></div>
<p>Now, let us apply the functions for three cv schemes to estimate the generalization error.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">##  ............................................................................
##  boostrap                                                                ####
<span class="co"># use boostrap sample to train, use all to test</span>
n &lt;-<span class="st"> </span><span class="kw">nrow</span>(ozone)
train &lt;-<span class="st"> </span><span class="kw">get_boostrap_mat</span>(<span class="dv">10</span>, n)
test &lt;-<span class="st"> </span><span class="kw">get_all_mat</span>(<span class="dv">10</span>, n)
bs &lt;-<span class="st"> </span><span class="kw">map2_dbl</span>(test, train, ge_ridge, <span class="dt">.data =</span> ozone, <span class="dt">lambda =</span> <span class="dv">5</span>)



##  ............................................................................
##  10-fold                                                                 ####
test &lt;-<span class="st"> </span><span class="kw">get_k_fold</span>(<span class="dv">10</span>, n)
train &lt;-<span class="st"> </span><span class="kw">map</span>(test, ~<span class="kw">setdiff</span>(<span class="dv">1</span>:n, .x))
kfold &lt;-<span class="st"> </span><span class="kw">map2_dbl</span>(test, train, ge_ridge, <span class="dt">.data =</span> ozone, <span class="dt">lambda =</span> <span class="dv">5</span>)

##  ............................................................................
##  out-of-boostrap                                                         ####
train &lt;-<span class="st"> </span><span class="kw">get_boostrap_mat</span>(<span class="dv">10</span>, n)
test &lt;-<span class="st"> </span><span class="kw">map</span>(test, ~<span class="kw">setdiff</span>(<span class="dv">1</span>:n, .x))
oob &lt;-<span class="st"> </span><span class="kw">map2_dbl</span>(test, train, ge_ridge, <span class="dt">.data =</span> ozone, <span class="dt">lambda =</span> <span class="dv">5</span>)</code></pre></div>
<p>The results are as follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">out &lt;-<span class="st"> </span><span class="kw">cbind</span>(bs, kfold, oob) %&gt;%
<span class="st">  </span><span class="kw">as_data_frame</span>() %&gt;%
<span class="st">  </span><span class="kw">gather</span>(key, value)

<span class="kw">ggplot</span>(out, <span class="kw">aes</span>(<span class="dt">y =</span> value, <span class="dt">x =</span> key)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_boxplot</span>()</code></pre></div>
<p><img src="comp_stats_summary_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
</div>
<div id="parameter-tuning" class="section level3">
<h3><span class="header-section-number">5.7.2</span> Parameter Tuning</h3>
<p>We want to use the scheme k-fold cross validation for parameter tuning with a lasso. We first calculate the test set error for <em>one</em> value of lamda (as we did above). Then, change the value of lamda and recompute the model and then test set error, so that the test set error becomes a function of lamda, as depicted below.</p>
<p><img src="figures/lasso_cv.png" width="650px" /></p>
<p>Then pick an optimal lamda, e.g. the one with the lowest test error (a bit arbitrary) or one according to some other rule (e.g. pick the least complex model that is within one standard error of the best model).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#&#39; Given lambda, compute the test set error with k folds</span>
find_lambda_kfold_one &lt;-<span class="st"> </span>function(lambda, k, n, .data, ...) {
  x_test &lt;-<span class="st"> </span><span class="kw">get_k_fold</span>(k, n)
  x_train  &lt;-<span class="st"> </span><span class="kw">get_complement</span>(x_test, n)
  <span class="kw">map2_dbl</span>(x_test, x_train, ge_ridge, <span class="dt">lambda =</span> lambda, <span class="dt">.data =</span> .data, ...) %&gt;%
<span class="st">    </span><span class="kw">mean</span>()
}

<span class="co">#&#39; Given a sequence of lambdas, return the corresponding test set errors</span>
find_lambda_kfold &lt;-<span class="st"> </span>function(seq, k, .data) {
  cv &lt;-<span class="st"> </span><span class="kw">map_dbl</span>(seq, find_lambda_kfold_one, 
                <span class="dt">k =</span> k, <span class="dt">n =</span> <span class="kw">nrow</span>(.data), <span class="dt">.data =</span> .data)
  results &lt;-<span class="st"> </span><span class="kw">data_frame</span>(<span class="dt">lambda =</span> seq, <span class="dt">cv_score =</span> cv)
  results
}</code></pre></div>
<p>We are almost done. Let us now compute the test set error that we use as an approximation of the generalization error and plot it against different values of lamda.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">find_lambda_kfold</span>(<span class="dt">seq =</span> <span class="kw">seq</span>(<span class="dv">5</span>, <span class="dv">30</span>, <span class="dt">by =</span> <span class="dv">3</span>), <span class="dv">100</span>, ozone) %&gt;%
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> lambda, <span class="dt">y =</span> cv_score)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_line</span>()</code></pre></div>
<p><img src="comp_stats_summary_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>That looks reasonable. We could improve on that by also showing the distribution of the test set error at various lambadas. This could by done by altering <code>find_lambda_kfold_one()</code> to not return the mean, but also the upper and lower 95% confidence interval.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="nonparametric-regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="bootstrap.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
